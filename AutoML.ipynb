{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a8ad87a",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "In this notebook, we will use AutoML library to address the NSL-KDD dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43aaf9e",
   "metadata": {},
   "source": [
    "### 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03ce0abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66835d67",
   "metadata": {},
   "source": [
    "#### 1.1 Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21fdf1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train data\n",
    "train = pd.read_csv('dataset/train_AutoML.csv')\n",
    "train.rename(columns={'attack_category': 'attack'}, inplace=True)\n",
    "\n",
    "# import test data\n",
    "test = pd.read_csv('dataset/test_AutoML.csv')\n",
    "test.rename(columns={'attack_category': 'attack'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbb4a77",
   "metadata": {},
   "source": [
    "#### 1.2 Feature category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49399e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = defaultdict(list)\n",
    "with open('dataset/feature_types.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        feature, category = line.strip().strip('.').split(': ')\n",
    "        feature_names[category].append(feature)\n",
    "\n",
    "# continuous features\n",
    "continuous_features = feature_names['continuous']\n",
    "continuous_features.remove('num_outbound_cmds')\n",
    "\n",
    "# binary features\n",
    "binary_features = ['land', 'logged_in', 'root_shell', 'su_attempted', 'is_host_login', 'is_guest_login']\n",
    "\n",
    "# nominal features\n",
    "nominal_features = list(set(feature_names['discrete'])-set(binary_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3bb273",
   "metadata": {},
   "source": [
    "#### 1.3 Ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "317bd777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "train[nominal_features] = enc.fit_transform(train[nominal_features])\n",
    "test[nominal_features] = enc.transform(test[nominal_features])\n",
    "\n",
    "# Separate feature/label\n",
    "X_train, y_train = train.iloc[:, :-1].to_numpy(), train.iloc[:, -1].to_numpy()\n",
    "X_test, y_test = test.iloc[:, :-1].to_numpy(), test.iloc[:, -1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038832de",
   "metadata": {},
   "source": [
    "### 2. ML modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8cfdc160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import (\n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    accuracy_score, \n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    matthews_corrcoef\n",
    ")\n",
    "\n",
    "\n",
    "def metrics_display(y_test, y_pred):\n",
    "\n",
    "    # Obtain confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Output classification metrics\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # print(f'ROC_AUC score: {roc_auc_score(y_test, y_pred_proba):.3f}')\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%')\n",
    "    print(f'Precision: {precision_score(y_test, y_pred)*100:.2f}%')\n",
    "    print(f'Detection rate: {recall_score(y_test, y_pred)*100:.2f}%')\n",
    "    print(f'False alarm rate: {fp / (tn+fp)*100}%')\n",
    "    print(f'MCC: {matthews_corrcoef(y_test, y_pred):.2f}')\n",
    "    \n",
    "    # Display confusion matrix\n",
    "    # ConfusionMatrixDisplay.from_predictions(y_test, y_pred, values_format='.5g', colorbar=False)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b534c9cb",
   "metadata": {},
   "source": [
    "#### 2.1 Default XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3405502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.13%\n",
      "Precision: 96.87%\n",
      "Detection rate: 78.16%\n",
      "False alarm rate: 3.3364226135310475%\n",
      "MCC: 0.74\n",
      "CPU times: total: 35 s\n",
      "Wall time: 3.26 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "import xgboost as xgb\n",
    "clf_xgb = xgb.XGBClassifier(eval_metric='auc', \n",
    "                            max_depth=4,\n",
    "                            learning_rate=0.3,\n",
    "                            reg_lambda=50,\n",
    "                            gamma=5,\n",
    "                            subsample=1,\n",
    "                            colsample_bytree=1,\n",
    "                            use_label_encoder=False,\n",
    "                            scale_pos_weight=50,\n",
    "                            n_jobs=-1,\n",
    "                            seed=42)\n",
    "\n",
    "clf_xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_xgb.predict(X_test)\n",
    "metrics_display(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb325dde",
   "metadata": {},
   "source": [
    "#### 2.2 AutoML with FLAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3ea1952a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 09-05 17:39:23] {2373} INFO - task = classification\n",
      "[flaml.automl: 09-05 17:39:23] {2375} INFO - Data split method: stratified\n",
      "[flaml.automl: 09-05 17:39:23] {2379} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 09-05 17:39:23] {2448} INFO - Minimizing error metric: 1-roc_auc\n",
      "[flaml.automl: 09-05 17:39:23] {2586} INFO - List of ML learners in AutoML Run: ['lgbm']\n",
      "[flaml.automl: 09-05 17:39:23] {2878} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:23] {3008} INFO - Estimated sufficient time budget=2831s. Estimated necessary time budget=3s.\n",
      "[flaml.automl: 09-05 17:39:23] {3055} INFO -  at 0.2s,\testimator lgbm's best error=0.0252,\tbest estimator lgbm's best error=0.0252\n",
      "[flaml.automl: 09-05 17:39:23] {2878} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:23] {3055} INFO -  at 0.3s,\testimator lgbm's best error=0.0183,\tbest estimator lgbm's best error=0.0183\n",
      "[flaml.automl: 09-05 17:39:23] {2878} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:23] {3055} INFO -  at 0.3s,\testimator lgbm's best error=0.0183,\tbest estimator lgbm's best error=0.0183\n",
      "[flaml.automl: 09-05 17:39:23] {2878} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:23] {3055} INFO -  at 0.3s,\testimator lgbm's best error=0.0049,\tbest estimator lgbm's best error=0.0049\n",
      "[flaml.automl: 09-05 17:39:23] {2878} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:23] {3055} INFO -  at 0.3s,\testimator lgbm's best error=0.0049,\tbest estimator lgbm's best error=0.0049\n",
      "[flaml.automl: 09-05 17:39:23] {2878} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:23] {3055} INFO -  at 0.4s,\testimator lgbm's best error=0.0019,\tbest estimator lgbm's best error=0.0019\n",
      "[flaml.automl: 09-05 17:39:23] {2878} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:23] {3055} INFO -  at 0.4s,\testimator lgbm's best error=0.0019,\tbest estimator lgbm's best error=0.0019\n",
      "[flaml.automl: 09-05 17:39:23] {2878} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:23] {3055} INFO -  at 0.4s,\testimator lgbm's best error=0.0019,\tbest estimator lgbm's best error=0.0019\n",
      "[flaml.automl: 09-05 17:39:23] {2878} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:23] {3055} INFO -  at 0.5s,\testimator lgbm's best error=0.0019,\tbest estimator lgbm's best error=0.0019\n",
      "[flaml.automl: 09-05 17:39:23] {2878} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:23] {3055} INFO -  at 0.5s,\testimator lgbm's best error=0.0019,\tbest estimator lgbm's best error=0.0019\n",
      "[flaml.automl: 09-05 17:39:23] {2878} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:24] {3055} INFO -  at 0.7s,\testimator lgbm's best error=0.0019,\tbest estimator lgbm's best error=0.0019\n",
      "[flaml.automl: 09-05 17:39:24] {2878} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:24] {3055} INFO -  at 1.0s,\testimator lgbm's best error=0.0003,\tbest estimator lgbm's best error=0.0003\n",
      "[flaml.automl: 09-05 17:39:24] {2878} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:24] {3055} INFO -  at 1.2s,\testimator lgbm's best error=0.0003,\tbest estimator lgbm's best error=0.0003\n",
      "[flaml.automl: 09-05 17:39:24] {2878} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:24] {3055} INFO -  at 1.4s,\testimator lgbm's best error=0.0003,\tbest estimator lgbm's best error=0.0003\n",
      "[flaml.automl: 09-05 17:39:24] {2878} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:24] {3055} INFO -  at 1.6s,\testimator lgbm's best error=0.0002,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl: 09-05 17:39:24] {2878} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:25] {3055} INFO -  at 1.9s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:25] {2878} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:25] {3055} INFO -  at 2.2s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:25] {2878} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:25] {3055} INFO -  at 2.5s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:25] {2878} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:26] {3055} INFO -  at 2.7s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:26] {2878} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:26] {3055} INFO -  at 2.9s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:26] {2878} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:26] {3055} INFO -  at 3.3s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:26] {2878} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:27] {3055} INFO -  at 3.9s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:27] {2878} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:27] {3055} INFO -  at 4.2s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:27] {2878} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:27] {3055} INFO -  at 4.5s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:27] {2878} INFO - iteration 24, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:28] {3055} INFO -  at 5.0s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:28] {2878} INFO - iteration 25, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:28] {3055} INFO -  at 5.4s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:28] {2878} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:29] {3055} INFO -  at 5.7s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:29] {2878} INFO - iteration 27, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:29] {3055} INFO -  at 6.3s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:29] {2878} INFO - iteration 28, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:29] {3055} INFO -  at 6.7s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:29] {2878} INFO - iteration 29, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:30] {3055} INFO -  at 7.0s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:30] {2878} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:30] {3055} INFO -  at 7.6s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:30] {2878} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:31] {3055} INFO -  at 8.2s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:31] {2878} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:32] {3055} INFO -  at 8.9s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:32] {2878} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:33] {3055} INFO -  at 9.7s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:33] {2878} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:33] {3055} INFO -  at 10.5s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:33] {2878} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:35] {3055} INFO -  at 11.9s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:35] {2878} INFO - iteration 36, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:35] {3055} INFO -  at 12.3s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 09-05 17:39:35] {2878} INFO - iteration 37, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:36] {3055} INFO -  at 13.6s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:36] {2878} INFO - iteration 38, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:37] {3055} INFO -  at 14.0s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:37] {2878} INFO - iteration 39, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:38] {3055} INFO -  at 15.1s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:38] {2878} INFO - iteration 40, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:38] {3055} INFO -  at 15.3s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:38] {2878} INFO - iteration 41, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:38] {3055} INFO -  at 15.6s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:38] {2878} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:40] {3055} INFO -  at 17.5s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:40] {2878} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl: 09-05 17:39:43] {3055} INFO -  at 20.1s,\testimator lgbm's best error=0.0000,\tbest estimator lgbm's best error=0.0000\n",
      "[flaml.automl: 09-05 17:39:45] {3315} INFO - retrain lgbm for 2.0s\n",
      "[flaml.automl: 09-05 17:39:45] {3322} INFO - retrained model: LGBMClassifier(colsample_bytree=0.35867716034909664,\n",
      "               learning_rate=0.2223931119028567, max_bin=1023,\n",
      "               min_child_samples=9, n_estimators=214, num_leaves=710,\n",
      "               reg_alpha=0.001975258376030875, reg_lambda=0.001848656226505261,\n",
      "               verbose=-1)\n",
      "[flaml.automl: 09-05 17:39:45] {2617} INFO - fit succeeded\n",
      "[flaml.automl: 09-05 17:39:45] {2618} INFO - Time taken to find the best model: 17.48887276649475\n",
      "[flaml.automl: 09-05 17:39:45] {2629} WARNING - Time taken to find the best model is 87% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "automl.fit(X_train, y_train, task=\"classification\", time_budget=20, estimator_list=['lgbm'],\n",
    "          log_file_name='automl.log', log_type='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "59e0a957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.84%\n",
      "Precision: 96.68%\n",
      "Detection rate: 61.42%\n",
      "False alarm rate: 2.790649778601586%\n",
      "MCC: 0.60\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = automl.predict(X_test)\n",
    "metrics_display(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92af26c",
   "metadata": {},
   "source": [
    "#### 2.3 Develop AutoML API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ba096d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "11324a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool(\"AutoML-LightGBM\")\n",
    "def auto_machine_learning(time_budget: float, metric: str, custom_hp: dict) -> str:\n",
    "    \"\"\"Hyperparameter tuning with FLAML library. The tunable hyperparameters for LightGBM are: \n",
    "    n_estimators, num_leaves, min_child_samples, learning_rate, \n",
    "    log_max_bin (logarithm of (max_bin + 1) with base 2), \n",
    "    colsample_bytree, reg_alpha, reg_lambda.\n",
    "    \n",
    "    Args:\n",
    "    ------\n",
    "    time_budget: A float number of the time budget in seconds.\n",
    "    metric: The optimization metric. \n",
    "            Built-in metric:\n",
    "                'accuracy': 1 - accuracy as the corresponding metric to minimize.\n",
    "                'roc_auc': minimize 1 - roc_auc_score. \n",
    "                'f1': minimize 1 - f1_score.\n",
    "            User-defined function:\n",
    "                A customized metric function that requires the following (input) signature, and returns the input \n",
    "                config’s value in terms of the metric you want to minimize, and a dictionary of auxiliary information \n",
    "                at your choice:\n",
    "                \n",
    "                    def custom_metric(\n",
    "                        X_val, y_val, estimator, labels,\n",
    "                        X_train, y_train, weight_val=None, weight_train=None,\n",
    "                        config=None, groups_val=None, groups_train=None,\n",
    "                    ):\n",
    "                        return metric_to_minimize, metrics_to_log\n",
    "                        \n",
    "                For example:\n",
    "                \n",
    "                    def custom_metric(\n",
    "                        X_val, y_val, estimator, labels,\n",
    "                        X_train, y_train, weight_val=None, weight_train=None,\n",
    "                        *args,\n",
    "                    ):\n",
    "                        from sklearn.metrics import log_loss\n",
    "                        import time\n",
    "\n",
    "                        start = time.time()\n",
    "                        y_pred = estimator.predict_proba(X_val)\n",
    "                        pred_time = (time.time() - start) / len(X_val)\n",
    "                        val_loss = log_loss(y_val, y_pred, labels=labels, sample_weight=weight_val)\n",
    "                        y_pred = estimator.predict_proba(X_train)\n",
    "                        train_loss = log_loss(y_train, y_pred, labels=labels, sample_weight=weight_train)\n",
    "                        alpha = 0.5\n",
    "                        return val_loss * (1 + alpha) - alpha * train_loss, {\n",
    "                            \"val_loss\": val_loss,\n",
    "                            \"train_loss\": train_loss,\n",
    "                            \"pred_time\": pred_time,\n",
    "                        }\n",
    "    custom_hp: The custom search space specified by user.It is a nested dict with keys being hyperparameter names, \n",
    "               and values are dicts of info (\"domain\" and \"init_value\") about the search space associated with the \n",
    "               hyperparameter. For example:\n",
    "               \n",
    "               custom_hp = {\n",
    "                         \"learning_rate\": {\n",
    "                             \"domain\": tune.loguniform(lower=0.01, upper=20.0),\n",
    "                             \"init_value\": 1\n",
    "                         }\n",
    "               }\n",
    "               \n",
    "               See the example below for the commonly used types of domains.\n",
    "               \n",
    "                # Sample a float uniformly between -5.0 and -1.0\n",
    "                tune.uniform(-5, -1),\n",
    "\n",
    "                # Sample a float uniformly between 3.2 and 5.4,\n",
    "                # rounding to increments of 0.2\n",
    "                tune.quniform(3.2, 5.4, 0.2),\n",
    "\n",
    "                # Sample a float uniformly between 0.0001 and 0.01, while\n",
    "                # sampling in log space\n",
    "                tune.loguniform(1e-4, 1e-2),\n",
    "\n",
    "                # Sample a float uniformly between 0.0001 and 0.1, while\n",
    "                # sampling in log space and rounding to increments of 0.00005\n",
    "                tune.qloguniform(1e-4, 1e-1, 5e-5),\n",
    "\n",
    "                # Sample a random float from a normal distribution with\n",
    "                # mean=10 and sd=2\n",
    "                tune.randn(10, 2),\n",
    "\n",
    "                # Sample a random float from a normal distribution with\n",
    "                # mean=10 and sd=2, rounding to increments of 0.2\n",
    "                tune.qrandn(10, 2, 0.2),\n",
    "\n",
    "                # Sample a integer uniformly between -9 (inclusive) and 15 (exclusive)\n",
    "                tune.randint(-9, 15),\n",
    "\n",
    "                # Sample a random uniformly between -21 (inclusive) and 12 (inclusive (!))\n",
    "                # rounding to increments of 3 (includes 12)\n",
    "                tune.qrandint(-21, 12, 3),\n",
    "\n",
    "                # Sample a integer uniformly between 1 (inclusive) and 10 (exclusive),\n",
    "                # while sampling in log space\n",
    "                tune.lograndint(1, 10),\n",
    "\n",
    "                # Sample a integer uniformly between 2 (inclusive) and 10 (inclusive (!)),\n",
    "                # while sampling in log space and rounding to increments of 2\n",
    "                tune.qlograndint(2, 10, 2),\n",
    "\n",
    "                # Sample an option uniformly from the specified choices\n",
    "                tune.choice([\"a\", \"b\", \"c\"])  \n",
    "                \n",
    "                \n",
    "    Outputs:\n",
    "    --------\n",
    "    record: log of tuning process, including the tuning history and the currently found \n",
    "            best configurations.\n",
    "    \"\"\"\n",
    "    \n",
    "    # AutoML object\n",
    "    automl = AutoML()\n",
    "    \n",
    "    # Tuning config\n",
    "    config = {\n",
    "        'task': 'classification',\n",
    "        'metric': metric,\n",
    "        'time_budget': time_budget,\n",
    "        'estimator_list': ['lgbm'],\n",
    "        'custom_hp': {'lgbm': custom_hp},\n",
    "        'log_file_name': 'automl.log',\n",
    "    }\n",
    "    \n",
    "    # Fitting\n",
    "    automl.fit(X_train, y_train, **config)\n",
    "    opt['model'] = automl\n",
    "    \n",
    "    # Tuning logs\n",
    "    with open(\"automl.log\", \"r\") as txt_file:\n",
    "        log = txt_file.readlines()\n",
    "    record = {\n",
    "        'log': log,\n",
    "        'best config': automl.best_config\n",
    "    }\n",
    "    \n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f658cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import tune\n",
    "time_budget = 10\n",
    "metric = 'accuracy'\n",
    "    \n",
    "custom_hp = {\n",
    "         \"learning_rate\": {\n",
    "             \"domain\": tune.loguniform(lower=0.01, upper=1),\n",
    "             \"init_value\": 0.1\n",
    "         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "97131e16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 09-05 22:50:57] {2373} INFO - task = classification\n",
      "[flaml.automl: 09-05 22:50:57] {2375} INFO - Data split method: stratified\n",
      "[flaml.automl: 09-05 22:50:57] {2379} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 09-05 22:50:57] {2448} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl: 09-05 22:50:57] {2586} INFO - List of ML learners in AutoML Run: ['lgbm']\n",
      "[flaml.automl: 09-05 22:50:57] {2878} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 09-05 22:50:58] {3008} INFO - Estimated sufficient time budget=4650s. Estimated necessary time budget=5s.\n",
      "[flaml.automl: 09-05 22:50:58] {3055} INFO -  at 0.3s,\testimator lgbm's best error=0.0518,\tbest estimator lgbm's best error=0.0518\n",
      "[flaml.automl: 09-05 22:50:58] {2878} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 09-05 22:50:58] {3055} INFO -  at 0.3s,\testimator lgbm's best error=0.0518,\tbest estimator lgbm's best error=0.0518\n",
      "[flaml.automl: 09-05 22:50:58] {2878} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 09-05 22:50:58] {3055} INFO -  at 0.4s,\testimator lgbm's best error=0.0412,\tbest estimator lgbm's best error=0.0412\n",
      "[flaml.automl: 09-05 22:50:58] {2878} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 09-05 22:50:58] {3055} INFO -  at 0.4s,\testimator lgbm's best error=0.0224,\tbest estimator lgbm's best error=0.0224\n",
      "[flaml.automl: 09-05 22:50:58] {2878} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 09-05 22:50:58] {3055} INFO -  at 0.4s,\testimator lgbm's best error=0.0224,\tbest estimator lgbm's best error=0.0224\n",
      "[flaml.automl: 09-05 22:50:58] {2878} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 09-05 22:50:58] {3055} INFO -  at 0.5s,\testimator lgbm's best error=0.0131,\tbest estimator lgbm's best error=0.0131\n",
      "[flaml.automl: 09-05 22:50:58] {2878} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 09-05 22:50:58] {3055} INFO -  at 0.5s,\testimator lgbm's best error=0.0131,\tbest estimator lgbm's best error=0.0131\n",
      "[flaml.automl: 09-05 22:50:58] {2878} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 09-05 22:50:58] {3055} INFO -  at 0.5s,\testimator lgbm's best error=0.0131,\tbest estimator lgbm's best error=0.0131\n",
      "[flaml.automl: 09-05 22:50:58] {2878} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 09-05 22:50:58] {3055} INFO -  at 0.6s,\testimator lgbm's best error=0.0063,\tbest estimator lgbm's best error=0.0063\n",
      "[flaml.automl: 09-05 22:50:58] {2878} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 09-05 22:50:58] {3055} INFO -  at 0.6s,\testimator lgbm's best error=0.0063,\tbest estimator lgbm's best error=0.0063\n",
      "[flaml.automl: 09-05 22:50:58] {2878} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl: 09-05 22:50:58] {3055} INFO -  at 0.9s,\testimator lgbm's best error=0.0024,\tbest estimator lgbm's best error=0.0024\n",
      "[flaml.automl: 09-05 22:50:58] {2878} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl: 09-05 22:50:58] {3055} INFO -  at 1.1s,\testimator lgbm's best error=0.0024,\tbest estimator lgbm's best error=0.0024\n",
      "[flaml.automl: 09-05 22:50:58] {2878} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl: 09-05 22:50:58] {3055} INFO -  at 1.2s,\testimator lgbm's best error=0.0024,\tbest estimator lgbm's best error=0.0024\n",
      "[flaml.automl: 09-05 22:50:58] {2878} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl: 09-05 22:50:59] {3055} INFO -  at 1.4s,\testimator lgbm's best error=0.0024,\tbest estimator lgbm's best error=0.0024\n",
      "[flaml.automl: 09-05 22:50:59] {2878} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl: 09-05 22:50:59] {3055} INFO -  at 1.7s,\testimator lgbm's best error=0.0024,\tbest estimator lgbm's best error=0.0024\n",
      "[flaml.automl: 09-05 22:50:59] {2878} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl: 09-05 22:50:59] {3055} INFO -  at 1.9s,\testimator lgbm's best error=0.0024,\tbest estimator lgbm's best error=0.0024\n",
      "[flaml.automl: 09-05 22:50:59] {2878} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl: 09-05 22:50:59] {3055} INFO -  at 2.0s,\testimator lgbm's best error=0.0024,\tbest estimator lgbm's best error=0.0024\n",
      "[flaml.automl: 09-05 22:50:59] {2878} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl: 09-05 22:51:00] {3055} INFO -  at 3.1s,\testimator lgbm's best error=0.0010,\tbest estimator lgbm's best error=0.0010\n",
      "[flaml.automl: 09-05 22:51:00] {2878} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl: 09-05 22:51:01] {3055} INFO -  at 4.3s,\testimator lgbm's best error=0.0010,\tbest estimator lgbm's best error=0.0010\n",
      "[flaml.automl: 09-05 22:51:01] {2878} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl: 09-05 22:51:02] {3055} INFO -  at 5.2s,\testimator lgbm's best error=0.0010,\tbest estimator lgbm's best error=0.0010\n",
      "[flaml.automl: 09-05 22:51:02] {2878} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl: 09-05 22:51:03] {3055} INFO -  at 5.7s,\testimator lgbm's best error=0.0010,\tbest estimator lgbm's best error=0.0010\n",
      "[flaml.automl: 09-05 22:51:03] {2878} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl: 09-05 22:51:05] {3055} INFO -  at 7.9s,\testimator lgbm's best error=0.0010,\tbest estimator lgbm's best error=0.0010\n",
      "[flaml.automl: 09-05 22:51:05] {2878} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl: 09-05 22:51:06] {3055} INFO -  at 9.0s,\testimator lgbm's best error=0.0010,\tbest estimator lgbm's best error=0.0010\n",
      "[flaml.automl: 09-05 22:51:07] {3315} INFO - retrain lgbm for 1.0s\n",
      "[flaml.automl: 09-05 22:51:07] {3322} INFO - retrained model: LGBMClassifier(colsample_bytree=0.6649148062238498,\n",
      "               learning_rate=0.14449463241010363, max_bin=255,\n",
      "               min_child_samples=3, n_estimators=189, num_leaves=20,\n",
      "               reg_alpha=0.0009765625, reg_lambda=0.006761362450996489,\n",
      "               verbose=-1)\n",
      "[flaml.automl: 09-05 22:51:07] {2617} INFO - fit succeeded\n",
      "[flaml.automl: 09-05 22:51:07] {2618} INFO - Time taken to find the best model: 3.1041369438171387\n"
     ]
    }
   ],
   "source": [
    "record = auto_machine_learning(time_budget, metric, custom_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b52cf89",
   "metadata": {},
   "source": [
    "#### Agent testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9de7a98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI, AzureChatOpenAI\n",
    "import os\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0)\n",
    "llm = AzureChatOpenAI(openai_api_base=\"https://abb-chcrc.openai.azure.com/\",\n",
    "            openai_api_version=\"2023-03-15-preview\",\n",
    "            openai_api_key=os.environ[\"OPENAI_API_KEY_AZURE\"],\n",
    "            openai_api_type=\"azure\",\n",
    "            deployment_name=\"gpt-35-turbo-0301\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "973ed85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "tools = [get_word_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b000b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage\n",
    "from langchain.agents import OpenAIFunctionsAgent\n",
    "system_message = SystemMessage(content=\"You are very powerful assistant, but bad at calculating lengths of words.\")\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(system_message=system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "45cca75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "10642a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f1630f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "Unrecognized request argument supplied: functions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [116]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhow many letters in the word educa?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\langchain\\chains\\base.py:290\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, *args, **kwargs)\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m[_output_key]\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags)[_output_key]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\langchain\\chains\\base.py:166\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    168\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    169\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    170\u001b[0m )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[0;32m    154\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    155\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    156\u001b[0m     inputs,\n\u001b[0;32m    157\u001b[0m )\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\langchain\\agents\\agent.py:987\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m--> 987\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    994\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m    995\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m    996\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m    997\u001b[0m         )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\langchain\\agents\\agent.py:792\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Take a single step in the thought-action-observation loop.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m \n\u001b[0;32m    788\u001b[0m \u001b[38;5;124;03mOverride this to take control of how the agent makes and acts on choices.\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m--> 792\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\langchain\\agents\\openai_functions_agent\\base.py:209\u001b[0m, in \u001b[0;36mOpenAIFunctionsAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_inputs)\n\u001b[0;32m    208\u001b[0m messages \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mto_messages()\n\u001b[1;32m--> 209\u001b[0m predicted_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_messages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m agent_decision \u001b[38;5;241m=\u001b[39m _parse_ai_message(predicted_message)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m agent_decision\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\langchain\\chat_models\\base.py:392\u001b[0m, in \u001b[0;36mBaseChatModel.predict_messages\u001b[1;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m     _stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(stop)\n\u001b[1;32m--> 392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\langchain\\chat_models\\base.py:342\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[1;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    337\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    341\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m--> 342\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\langchain\\chat_models\\base.py:121\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    120\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 121\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    122\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    123\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    125\u001b[0m ]\n\u001b[0;32m    126\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\langchain\\chat_models\\base.py:111\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, **kwargs)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 111\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m         )\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\langchain\\chat_models\\base.py:255\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m     )\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported:\n\u001b[1;32m--> 255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\langchain\\chat_models\\openai.py:369\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m     message \u001b[38;5;241m=\u001b[39m _convert_dict_to_message(\n\u001b[0;32m    362\u001b[0m         {\n\u001b[0;32m    363\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: inner_completion,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m         }\n\u001b[0;32m    367\u001b[0m     )\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations\u001b[38;5;241m=\u001b[39m[ChatGeneration(message\u001b[38;5;241m=\u001b[39mmessage)])\n\u001b[1;32m--> 369\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\langchain\\chat_models\\openai.py:317\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\tenacity\\__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    312\u001b[0m is_explicit_retry \u001b[38;5;241m=\u001b[39m fut\u001b[38;5;241m.\u001b[39mfailed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fut\u001b[38;5;241m.\u001b[39mexception(), TryAgain)\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry(retry_state)):\n\u001b[1;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter(retry_state)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\concurrent\\futures\\_base.py:437\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\concurrent\\futures\\_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    392\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\langchain\\chat_models\\openai.py:315\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\openai\\api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    217\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    218\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\openai\\api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    612\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    613\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    614\u001b[0m         )\n\u001b[0;32m    615\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    616\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    625\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    626\u001b[0m     )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\defcon\\lib\\site-packages\\openai\\api_requestor.py:682\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    680\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    683\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: Unrecognized request argument supplied: functions"
     ]
    }
   ],
   "source": [
    "agent_executor.run(\"how many letters in the word educa?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b85f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
